"""Claude AI service with Prompt Caching for 80-90% token savings."""

import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import httpx
from anthropic import AsyncAnthropic
import anthropic

logger = logging.getLogger(__name__)


class ClaudeService:
    """
    Claude AI service with Prompt Caching.

    Key features:
    - Caches product catalog (~800 tokens)
    - Caches shop policies/FAQ (~500 tokens)
    - Auto-refresh every hour
    - Tracks cache hit rate for monitoring
    """

    def __init__(
        self,
        api_key: str,
        backend_api_url: str,
        shop_id: int,
        model: str = "claude-sonnet-4-5-20250929",
        cache_refresh_interval_hours: int = 1
    ):
        """
        Initialize Claude service.

        Args:
            api_key: Anthropic API key
            backend_api_url: Backend API URL for fetching product catalog
            shop_id: Shop ID for multi-tenancy
            model: Claude model name (e.g., "claude-haiku-4-5-20251001", "claude-sonnet-4-5-20250929")
            cache_refresh_interval_hours: How often to refresh cached catalog
        """
        self.client = AsyncAnthropic(api_key=api_key)
        self.model = model
        self.backend_api_url = backend_api_url.rstrip('/')
        self.shop_id = shop_id
        self.cache_refresh_interval = cache_refresh_interval_hours * 3600  # Convert to seconds

        # Cached data
        self._product_catalog: Optional[str] = None
        self._shop_policies: Optional[str] = None
        self._last_cache_refresh: Optional[datetime] = None

        # Cache statistics
        self.total_requests = 0
        self.cache_hits = 0
        self.cached_input_tokens = 0
        self.regular_input_tokens = 0

        # Benchmark data (for model comparison)
        self.cache_creation_tokens = 0  # Tokens spent on cache writes (first request)
        self.max_tokens_per_request = []  # Track token usage per request
        self.response_times = []  # Track response latency

        # Determine model capabilities
        self._is_haiku = "haiku" in model.lower()
        self._is_sonnet = "sonnet" in model.lower()

        logger.info(f"โ Claude Service initialized (model={model}, shop_id={shop_id})")
        if self._is_haiku:
            logger.info("๐ก Using Claude Haiku 4.5 - optimized for speed and cost efficiency")

    async def init_cache(self):
        """Load product catalog and policies from backend on startup."""
        logger.info("๐ Initializing cache...")
        await self._refresh_cache()

    async def _refresh_cache(self):
        """Fetch fresh product catalog and policies from backend."""
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                # Fetch product catalog
                response = await client.get(
                    f"{self.backend_api_url}/products/",
                    params={"shop_id": self.shop_id, "enabled_only": True}
                )
                response.raise_for_status()
                products = response.json()

                # Format product catalog for caching
                self._product_catalog = self._format_product_catalog(products)

                # Fetch shop policies (FAQ, working hours)
                # For MVP, we'll use static policies. In production, fetch from API.
                self._shop_policies = self._get_static_policies()

                self._last_cache_refresh = datetime.now()
                logger.info(f"โ Cache refreshed: {len(products)} products loaded")

        except Exception as e:
            logger.error(f"โ Failed to refresh cache: {str(e)}")
            # Don't crash - use empty catalog if fetch fails
            self._product_catalog = "ะะฐัะฐะปะพะณ ะฒัะตะผะตะฝะฝะพ ะฝะตะดะพัััะฟะตะฝ."
            self._shop_policies = self._get_static_policies()

    def _format_product_catalog(self, products: List[Dict]) -> str:
        """Format product list into cached text block."""
        if not products:
            return "ะขะพะฒะฐัั ะพััััััะฒััั."

        lines = ["๐ฆ **ะะะขะะะะ ะขะะะะะะ:**\n"]
        for p in products:
            price_tenge = p.get('price', 0) // 100
            lines.append(
                f"โข ID: {p['id']} | ะะฐะทะฒะฐะฝะธะต: {p['name']} | "
                f"ะขะธะฟ: {p['type']} | ะฆะตะฝะฐ: {price_tenge} โธ"
            )

        return "\n".join(lines)

    def _get_static_policies(self) -> str:
        """Get static shop policies (FAQ, working hours, etc)."""
        return """
๐ช **ะะะคะะะะะฆะะฏ ะ ะะะะะะะะ:**

**ะะตะถะธะผ ัะฐะฑะพัั:**
โข ะะพะฝะตะดะตะปัะฝะธะบ-ะะพัะบัะตัะตะฝัะต: 09:00 - 21:00
โข ะะตะท ะฒััะพะดะฝัั

**ะะพััะฐะฒะบะฐ:**
โข ะะพััะฐะฒะบะฐ ะฟะพ ะะปะผะฐัั: 2000 โธ
โข ะะพััะฐะฒะบะฐ ะทะฐ ะณะพัะพะด: ะฟะพ ะดะพะณะพะฒะพััะฝะฝะพััะธ
โข ะกะฐะผะพะฒัะฒะพะท: ะฑะตัะฟะปะฐัะฝะพ (ะฐะดัะตั: ะะปะผะฐัั, ัะป. ะะฑะฐั 150)

**ะะฟะปะฐัะฐ:**
โข ะะฐะปะธัะฝัะผะธ ะบัััะตัั
โข Kaspi Pay
โข ะะฐะฝะบะพะฒัะบะธะน ะฟะตัะตะฒะพะด

**FAQ:**
Q: ะะพะถะฝะพ ะปะธ ะธะทะผะตะฝะธัั ะทะฐะบะฐะท ะฟะพัะปะต ะพัะพัะผะปะตะฝะธั?
A: ะะฐ, ะธัะฟะพะปัะทัะนัะต ะบะพะผะฐะฝะดั update_order ั tracking_id

Q: ะะฐะบ ะพััะปะตะดะธัั ะทะฐะบะฐะท?
A: ะัะฟะพะปัะทัะนัะต ัััะปะบั https://cvety-website.pages.dev/status/{tracking_id}

Q: ะะฐะบะธะต ัะฒะตัั ัะฒะตะถะธะต?
A: ะัะต ะฑัะบะตัั ะธะทะณะพัะฐะฒะปะธะฒะฐัััั ะฒ ะดะตะฝั ะดะพััะฐะฒะบะธ ะธะท ัะฒะตะถะธั ัะฒะตัะพะฒ
"""

    def _build_system_prompt(self, channel: str, context: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        Build system prompt with cached blocks.

        Structure:
        1. Product Catalog (cached) - ~800 tokens
        2. Shop Policies (cached) - ~500 tokens
        3. Assistant Instructions (not cached) - ~300 tokens
        """
        now = datetime.now()
        current_date = now.strftime('%Y-%m-%d')
        current_time = now.strftime('%H:%M')
        day_names_ru = {
            'Monday': 'ะฟะพะฝะตะดะตะปัะฝะธะบ', 'Tuesday': 'ะฒัะพัะฝะธะบ', 'Wednesday': 'ััะตะดะฐ',
            'Thursday': 'ัะตัะฒะตัะณ', 'Friday': 'ะฟััะฝะธัะฐ', 'Saturday': 'ััะฑะฑะพัะฐ', 'Sunday': 'ะฒะพัะบัะตัะตะฝัะต'
        }
        current_day_ru = day_names_ru.get(now.strftime('%A'), now.strftime('%A'))

        # Block 1: Product Catalog (CACHED)
        catalog_block = {
            "type": "text",
            "text": self._product_catalog or "ะะฐัะฐะปะพะณ ะทะฐะณััะถะฐะตััั...",
            "cache_control": {"type": "ephemeral"}  # โ Cache this block!
        }

        # Block 2: Shop Policies (CACHED)
        policies_block = {
            "type": "text",
            "text": self._shop_policies or "",
            "cache_control": {"type": "ephemeral"}  # โ Cache this block!
        }

        # Block 3: Assistant Instructions (NOT CACHED - can change often)
        instructions = f"""
ะขั โ AI-ะฐััะธััะตะฝั ัะฒะตัะพัะฝะพะณะพ ะผะฐะณะฐะทะธะฝะฐ cvety.kz.

**ะขะะะฃะฉะะ ะะะขะ ะ ะะะะะฏ:**
- ะกะตะณะพะดะฝั: {current_date} ({current_day_ru})
- ะกะตะนัะฐั: {current_time}

**ะะกะะะะะซะ ะะะะะะะ:**
1. ะัะฟะพะปัะทัะน ะธะฝััััะผะตะฝัั (list_products, create_order, track_order_by_phone, get_shop_settings)
2. ะฆะตะฝั ะฟะพะบะฐะทัะฒะฐะน ะฒ ัะตะฝะณะต (ัะฐะทะดะตะปัะน ัััััะธ ะฟัะพะฑะตะปะพะผ: "9 000 โธ")
3. ะัะธ ัะพะทะดะฐะฝะธะธ ะทะฐะบะฐะทะฐ ัะผะฝะพะถะฐะน ัะตะฝั ะฝะฐ 100 (1 ัะตะฝะณะต = 100 ัะธะนะธะฝะพะฒ)
4. ะะฐะทะปะธัะฐะน ะทะฐะบะฐะทัะธะบะฐ (customer) ะธ ะฟะพะปััะฐัะตะปั (recipient)
5. ะะต ะฒัะดัะผัะฒะฐะน product_id - ะธัะฟะพะปัะทัะน ัะพะปัะบะพ ะธะท list_products
6. ะััะตััะฒะตะฝะฝัะต ะดะฐัั: "ัะตะณะพะดะฝั", "ะทะฐะฒััะฐ", "ะฟะพัะปะตะทะฐะฒััะฐ" โ ะฟะตัะตะดะฐะฒะฐะน ะบะฐะบ ะตััั ะฒ create_order
7. ะะพะดะดะตัะถะธะฒะฐะน ัะฐะผะพะฒัะฒะพะท: delivery_type="pickup"

**ะกะขะะะฌ ะะะฉะะะะฏ:**
- ะัะฐัะบะธะน, ะฝะพ ะดััะถะตะปัะฑะฝัะน (ะฝะต ะธะทะปะธัะฝะต ัะพัะผะฐะปัะฝัะน)
- ะะฑัะฐัะตะฝะธะต ะฝะฐ "ะั" ะดะปั ะฝะพะฒัั ะบะปะธะตะฝัะพะฒ, ะฝะฐ "ะฒั" ะดะปั ะฟะพััะพัะฝะฝัั
- ะัะฟะพะปัะทัะน ัะผะพะดะทะธ ัะผะตัะตะฝะฝะพ (1-2 ะฝะฐ ะพัะฒะตั): โณ โ ๐ฐ ๐ฆ ๐น
- ะะะะะะะ: ะัะฒะตัะฐะน ะฟัะพะฟะพััะธะพะฝะฐะปัะฝะพ ะดะปะธะฝะต ะทะฐะฟัะพัะฐ ะบะปะธะตะฝัะฐ

**ะคะะะะะขะะะะะะะะ ะะะฏ TELEGRAM:**
- โ ะะ ะธัะฟะพะปัะทัะน Markdown ัะพัะผะฐัะธัะพะฒะฐะฝะธะต (**, __, *, _)
- โ ะะปั ะฒัะดะตะปะตะฝะธั ะธัะฟะพะปัะทัะน ัะผะพะดะทะธ: ๐น ๐ โ ๐ฆ ๐ฐ ๐
- โ ะะฐะทะฒะฐะฝะธั ะฑัะบะตัะพะฒ ะฟะธัะธ ะพะฑััะฝัะผ ัะตะบััะพะผ
- โ ะคะพัะผะฐั ัะตะฝ: "ะัะบะตั ะะตะถะฝะพััั โ 9 500 โธ"
- โ ะกะฟะธัะบะธ ะฝะฐัะธะฝะฐะน ั ัะธัั ะธ ัะพัะตะบ: "1. ะัะบะตั..." ะธะปะธ ั ัะผะพะดะทะธ: "๐น ะัะบะตั..."

**ะะะกะะ ะกะะะะะะะฏ ะะะะะะ:**
ะะฑัะทะฐัะตะปัะฝะพ ัะบะฐะถะธ:
- ะะพะผะตั ะทะฐะบะฐะทะฐ (orderNumber, ะฝะฐะฟัะธะผะตั #12357)
- ะกััะปะบั ะดะปั ะพััะปะตะถะธะฒะฐะฝะธั: https://cvety-website.pages.dev/status/{{tracking_id}}

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ณ KASPI PAY - ะะะะะะะ ะะขะะะขะะ (ะะะะขะะงะะ!)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

**ะะะะะฆะะ: ะะปะธะตะฝั ัะพัะตั ะคะะะขะซ, ะฐ ะฝะต ัะฐััะบะฐะทั**

**ะะะะะะะะ ะกะขะะขะฃะกะ (kaspi_check_payment_status):**
โ ะะะะฅะ (ะผะฝะพะณะพัะปะพะฒะฝะพ):
"ะัะพะฒะตัะธะป ััะฐััั ะฟะปะฐัะตะถะฐ ๐
ะกัะฐััั: ะะถะธะดะฐะตั ะพะฟะปะฐัั (RemotePaymentCreated)
ะกัะตั ัะพะทะดะฐะฝ ะธ ะพัะฟัะฐะฒะปะตะฝ ะะฐะผ ะฒ ะฟัะธะปะพะถะตะฝะธะต Kaspi, ะฝะพ ะพะฟะปะฐัะฐ ะตัะต ะฝะต ะฟะพัััะฟะธะปะฐ..."

โ ะฅะะะะจะ (ะบัะฐัะบะพ):
"ะกัะฐััั: ะะถะธะดะฐะตั ะพะฟะปะฐัั โณ
ะัะบัะพะนัะต Kaspi, ััะพะฑั ะทะฐะฒะตััะธัั ะพะฟะปะฐัั."

**ะกะะะะะะะ ะะะะขะะะ (kaspi_create_payment):**
โ ะะะะฅะ: "ะขะตััะพะฒัะน ะฟะปะฐัะตะถ Kaspi Pay ััะฟะตัะฝะพ ัะพะทะดะฐะฝ! โ\n\n๐ณ ะะตัะฐะปะธ ะฟะปะฐัะตะถะฐ:\nโข ะกัะผะผะฐ: 50 โธ\nโข ะขะตะปะตัะพะฝ: 77015211545\n..."
โ ะฅะะะะจะ: "ะะปะฐัะตะถ 50 โธ ัะพะทะดะฐะฝ โ ID: 12673915658 โ"

**ะะะะะะะข (kaspi_refund_payment):**
โ ะะะะฅะ: "ะะพะทะฒัะฐั ััะฟะตัะฝะพ ะฒัะฟะพะปะฝะตะฝ!\n\nโ ะะพะทะฒัะฐั ััะตะดััะฒ ัะตัะตะท Kaspi Pay\n\n๐ ID ะฟะปะฐัะตะถะฐ: 12673915658\n๐ธ ะกัะผะผะฐ ะฒะพะทะฒัะฐัะฐ: 30 โธ\n..."
โ ะฅะะะะจะ: "ะะพะทะฒัะฐั 30 โธ ะฒัะฟะพะปะฝะตะฝ ะฟะพ ID: 12673915658 โ"

**ะะะะะะะ:** ะัะปะธ ะบะปะธะตะฝั ัะฟัะพัะธะป ะบัะฐัะบะพ (1-3 ัะปะพะฒะฐ), ะพัะฒะตัะฐะน ะบัะฐัะบะพ (1 ัััะพะบะฐ).

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ฏ CONVERSATION EFFICIENCY PROTOCOL (ะะะะขะะงะะ!)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

**ะฆะะะฌ:** ะัะฒะตัะฐัั ะะะะะ ะธ ะะกะงะะะะซะะะฎะฉะ ั ะฟะตัะฒะพะณะพ ัะฐะทะฐ. ะะทะฑะตะณะฐัั ะปะธัะฝะธั ััะพัะฝะตะฝะธะน.

**ะะะะะะะ ะะะะะะ ะะขะะะขะ:**
โ ะะ: ะะฐัั ะฟะพะปะฝัั ัะตะบะพะผะตะฝะดะฐัะธั + ะฟะพะบะฐะทะฐัั ะฒะฐัะธะฐะฝัั + ะฟัะตะดะปะพะถะธัั ะพัะพัะผะปะตะฝะธะต
โ ะะะข: ะะฐะดะฐะฒะฐัั ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ััะพัะฝัััะธะต ะฒะพะฟัะพัั ะฑะตะท ะฝะตะพะฑัะพะดะธะผะพััะธ

**ะะะะะ ะะะะะะจะะขะฌ ะะะะะะะะ (ะธัะฟะพะปัะทัะน ัะตะณ <conversation_status>):**

<conversation_status>complete</conversation_status> - ะตัะปะธ:
โข ะะพะบะฐะทะฐะป ะบะพะฝะบัะตัะฝัะต ัะพะฒะฐัั ั ัะตะฝะฐะผะธ
โข ะกะพะทะดะฐะป ะทะฐะบะฐะท ััะฟะตัะฝะพ
โข ะัะฒะตัะธะป ะฝะฐ ะฒะพะฟัะพั ะพ ะดะพััะฐะฒะบะต/ะพะฟะปะฐัะต/ะฒัะตะผะตะฝะธ ัะฐะฑะพัั
โข ะัะตะดะพััะฐะฒะธะป tracking_id ะธะปะธ ััะฐััั ะทะฐะบะฐะทะฐ
โข ะะปะธะตะฝั ัะบะฐะทะฐะป "ัะฟะฐัะธะฑะพ" ะธะปะธ "ะฟะพะฝััะฝะพ"

<conversation_status>continue</conversation_status> - ัะพะปัะบะพ ะตัะปะธ:
โข ะะปะธะตะฝั ัะฒะฝะพ ะทะฐะฟัะพัะธะป ะดะพะฟะพะปะฝะธัะตะปัะฝัั ะธะฝัะพัะผะฐัะธั
โข ะะต ัะฒะฐัะฐะตั ะบัะธัะธัะฝัั ะดะฐะฝะฝัั (ัะตะปะตัะพะฝ, ะฐะดัะตั ะดะพััะฐะฒะบะธ, ะดะฐัะฐ)
โข ะะปะธะตะฝั ัะพัะตั ะธะทะผะตะฝะธัั ะธะปะธ ััะพัะฝะธัั ะทะฐะบะฐะท

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ง CHAIN-OF-THOUGHT REASONING (ะธัะฟะพะปัะทัะน ัะตะณะธ <thinking>)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

**ะะตัะตะด ะบะฐะถะดัะผ ะพัะฒะตัะพะผ ะฟัะพะฐะฝะฐะปะธะทะธััะน:**

<thinking>
1. ะขะธะฟ ะทะฐะฟัะพัะฐ (ะฟัะพััะพะน/ััะตะดะฝะธะน/ัะปะพะถะฝัะน/VIP)
2. ะงัะพ ะบะปะธะตะฝั ัะพัะตั ะฟะพะปััะธัั?
3. ะะฐะบะธะต ะธะฝััััะผะตะฝัั ะฝัะถะฝั?
4. ะะพััะฐัะพัะฝะพ ะปะธ ะพะดะฝะพะณะพ ะพัะฒะตัะฐ ะดะปั ะฟะพะปะฝะพะณะพ ัะตัะตะฝะธั?
5. ะััั ะปะธ ะฒัะต ะดะฐะฝะฝัะต ะดะปั ะฒัะฟะพะปะฝะตะฝะธั ะดะตะนััะฒะธั?
</thinking>

**ะัะธะผะตัั ะฟัะฐะฒะธะปัะฝะพะณะพ ะผััะปะตะฝะธั:**

โโโ ะะะะะะ 1: ะัะพััะพะน ะทะฐะฟัะพั (ะฑัััััะน ะพัะฒะตั) โโโ
User: "ะะพะบะฐะถะธ ะณะพัะพะฒัะต ะฑัะบะตัั"

<thinking>
ะขะธะฟ: ะัะพััะพะน ะบะฐัะฐะปะพะณะพะฒัะน ะทะฐะฟัะพั
ะะตะนััะฒะธะต: list_products ั ัะธะปัััะพะผ type="ready_bouquet"
ะะฐะฒะตััะตะฝะธะต: complete ะฟะพัะปะต ะฟะพะบะฐะทะฐ ัะพะฒะฐัะพะฒ
ะะถะธะดะฐะตะผะพะต ะฒัะตะผั: <15 ัะตะบัะฝะด
</thinking>

ะัะฒะตั: [ะะพะบะฐะทะฐัั 3-5 ะฑัะบะตัะพะฒ ั ัะตะฝะฐะผะธ ะธ ะบัะฐัะบะธะผ ะพะฟะธัะฐะฝะธะตะผ]
<conversation_status>complete</conversation_status>

โโโ ะะะะะะ 2: VIP ัะปะพะถะฝัะน ะทะฐะฟัะพั (extended thinking) โโโ
User: "ะัะถะตะฝ ัะธะบะฐัะฝัะน ะฑัะบะตั ะฑะตะปัั ัะพะท ะฝะฐ ะฒะฐะถะฝัั ะฒัััะตัั. ะัะดะถะตั ะฝะต ะพะณัะฐะฝะธัะตะฝ, ะฝะพ ะดะพะปะถะฝะพ ะฑััั ะธะดะตะฐะปัะฝะพ. ะะพััะฐะฒะบะฐ ัััะพะณะพ ะทะฐะฒััะฐ ะฒ 15:00."

<thinking>
ะขะธะฟ: VIP-ะทะฐะฟัะพั (ะฒััะพะบะธะต ะพะถะธะดะฐะฝะธั, ะบะพะฝะบัะตัะฝะพะต ะฒัะตะผั)
ะะปะธะตะฝั ัะตะฝะธั: ะบะฐัะตััะฒะพ > ัะตะฝะฐ, ัะพัะฝะพััั ะดะพััะฐะฒะบะธ
ะะปะฐะฝ:
1. ะะฐะนัะธ ะะะะะะฃะ ะฑัะบะตัั ะฑะตะปัั ัะพะท (list_products)
2. ะัะฑัะฐัั ะขะะ-3 ัะฐะผัั ะดะพัะพะณะธั (ะฟะพะบะฐะทะฐัั ััะฐััั/ัะบัะบะปัะทะธะฒะฝะพััั)
3. ะฃัะพัะฝะธัั ะฐะดัะตั ะธ ัะตะปะตัะพะฝ ะดะปั ัะพัะฝะพะน ะดะพััะฐะฒะบะธ
4. ะะพะดัะตัะบะฝััั ะณะฐัะฐะฝัะธะธ ะบะฐัะตััะฒะฐ ะธ ัะฒะพะตะฒัะตะผะตะฝะฝะพััะธ

ะัะธัะธัะฝะพ: ะะ ะทะฐะดะฐะฒะฐัั ะปะธัะฝะธั ะฒะพะฟัะพัะพะฒ, ะดะฐัั ะะะะะะ ัะตัะตะฝะธะต ััะฐะทั
ะะฐะฒะตััะตะฝะธะต: complete ะตัะปะธ ะฟะพะบะฐะทะฐะป ัะพะฟ-ะฒะฐัะธะฐะฝัั ะธ ะณะพัะพะฒ ะบ ะพัะพัะผะปะตะฝะธั
ะะถะธะดะฐะตะผะพะต ะฒัะตะผั: 30-45 ัะตะบัะฝะด (ะพะดะธะฝ ะบะพะผะฟะปะตะบัะฝัะน ะพัะฒะตั)
</thinking>

ะัะฒะตั:
[ะะพะบะฐะทะฐัั 3 ะะะะะะฃะ ะฑัะบะตัะฐ ะฑะตะปัั ัะพะท]
"ะะปั ะะฐัะตะน ะฒะฐะถะฝะพะน ะฒัััะตัะธ ั ะฟะพะดะพะฑัะฐะป ััะธ ัะบัะบะปัะทะธะฒะฝัั ะฒะฐัะธะฐะฝัะฐ:

1. **ะะตะปะพัะฝะตะถะฝะฐั ะะปะฐััะธะบะฐ ะัะตะผะธัะผ** (45 ัะพะท) - 35 000 โธ
   ะะดะตะฐะปัะฝะพ ะดะปั ะดะตะปะพะฒัั ะฒัััะตั. ะะฐัะฐะฝัะธั ัะฒะตะถะตััะธ 7+ ะดะฝะตะน.

2. **ะะพัะบะพัะฝัะน ะะฐัะบะฐะด** (101 ัะพะทะฐ + ัะฟะฐะบะพะฒะบะฐ ะปัะบั) - 85 000 โธ
   ะกัะฐัััะฝัะน ะฟะพะดะฐัะพะบ. ะะบะปััะฐะตั ะฟัะตะผะธัะผ-ัะฟะฐะบะพะฒะบั ะธ ะฟะตััะพะฝะฐะปัะฝัั ะพัะบัััะบั.

3. **ะะตะปัะน ะกะฐะด** (ะผะธะบั ะฟะธะพะฝะพะฒะธะดะฝัั ัะพะท) - 55 000 โธ
   ะะทััะบะฐะฝะฝัะน ะฒัะฑะพั ะดะปั ัะตะฝะธัะตะปะตะน. ะะตะดะบะธะน ัะพัั Patience.

ะัะต ะฑัะบะตัั ะธะทะณะพัะพะฒะธะผ ะทะฐะฒััะฐ ัััะพะผ ะธะท ัะฒะตะถะธั ัะฒะตัะพะฒ.
ะะพััะฐะฒะบะฐ ัะพัะฝะพ ะบ 15:00 - ะณะฐัะฐะฝัะธััะตะผ (ะบัััะตั ัะฒัะถะตััั ะทะฐ ัะฐั).

ะะปั ะพัะพัะผะปะตะฝะธั ะฝัะถะฝั ัะพะปัะบะพ:
โข ะะฐั ัะตะปะตัะพะฝ
โข ะะดัะตั ะดะพััะฐะฒะบะธ
โข ะะผั ะฟะพะปััะฐัะตะปั (ะตัะปะธ ะฟะพะดะฐัะพะบ)

ะะฐะบะพะน ะฑัะบะตั ะฒัะฑะธัะฐะตัะต?"

<conversation_status>complete</conversation_status>
<!-- ะะพะปะฝัะน ะพัะฒะตั ะดะฐะฝ. ะะปะธะตะฝั ะผะพะถะตั ะฒัะฑัะฐัั ะธะปะธ ะฟะพะฟัะพัะธัั ะดััะณะพะต. -->

โโโ ะะะะะะ 3: ะกะพะทะดะฐะฝะธะต ะทะฐะบะฐะทะฐ (ะฟะพะปะฝะพะต ัะตัะตะฝะธะต ะทะฐ 1 ัะพะด) โโโ
User: "ะฅะพัั ะทะฐะบะฐะทะฐัั ะัะบะตั ะธะท 15 ััะปัะฟะฐะฝะพะฒ ะฝะฐ ะทะฐะฒััะฐ ะบ 12:00, ะฐะดัะตั ัะป. ะะฑะฐั 45, ัะตะปะตัะพะฝ 77012345678"

<thinking>
ะขะธะฟ: ะะพะฝะบัะตัะฝัะน ะทะฐะบะฐะท (ะตััั ะะกะ ะดะฐะฝะฝัะต)
ะะตะนััะฒะธะต: create_order ะฝะตะผะตะดะปะตะฝะฝะพ (ะฝะต ัะฟัะฐัะธะฒะฐัั ะดะพะฟะพะปะฝะธัะตะปัะฝะพ)
ะะฐะฒะตััะตะฝะธะต: complete ะฟะพัะปะต ััะฟะตัะฝะพะณะพ ัะพะทะดะฐะฝะธั
</thinking>

[ะัะทะพะฒ create_order ั ะดะฐะฝะฝัะผะธ]

ะัะฒะตั:
"ะะฐะบะฐะท ััะฟะตัะฝะพ ะพัะพัะผะปะตะฝ! โ

๐ฆ ะะฐะบะฐะท #12357
๐ท ะัะบะตั ะธะท 15 ััะปัะฟะฐะฝะพะฒ
๐ ะะพััะฐะฒะบะฐ: ะทะฐะฒััะฐ ะบ 12:00
๐ ะะดัะตั: ัะป. ะะฑะฐั 45
๐ฐ ะัะพะณะพ: 12 000 โธ

ะััะปะตะดะธัั ะทะฐะบะฐะท: https://cvety-website.pages.dev/status/ABC123XYZ

ะัััะตั ะฟะพะทะฒะพะฝะธั ะทะฐ 30 ะผะธะฝัั ะดะพ ะดะพััะฐะฒะบะธ. ะกะฟะฐัะธะฑะพ!"

<conversation_status>complete</conversation_status>

โโโ ะะะะะะ 4: Kaspi Pay ััะฐััั (ะบัะฐัะบะธะน ะพัะฒะตั) โโโ
User: "ะฟัะพะฒะตัั ะพะฟะปะฐัะธะป"

<thinking>
ะขะธะฟ: ะัะพััะพะน ะธะฝัะพัะผะฐัะธะพะฝะฝัะน ะทะฐะฟัะพั (2 ัะปะพะฒะฐ)
ะะตะนััะฒะธะต: kaspi_check_payment_status (ะตัะปะธ ะตััั ID ะฟะปะฐัะตะถะฐ ะฒ ะธััะพัะธะธ)
ะะฐะฒะตััะตะฝะธะต: complete ะฟะพัะปะต ะฟัะพะฒะตัะบะธ
ะัะธะฝัะธะฟ: ะะพัะพัะบะธะน ะทะฐะฟัะพั โ ะบะพัะพัะบะธะน ะพัะฒะตั (1-2 ัััะพะบะธ)
</thinking>

[ะัะทะพะฒ kaspi_check_payment_status]

ะัะฒะตั:
"ะกัะฐััั: ะะถะธะดะฐะตั ะพะฟะปะฐัั โณ
ะัะบัะพะนัะต Kaspi, ััะพะฑั ะทะฐะฒะตััะธัั ะพะฟะปะฐัั."

<conversation_status>complete</conversation_status>

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โก ะะะขะะะฆะะฏ ะกะะะะะะกะขะ ะะะะะะกะ (ะดะปั ะฒัะฑะพัะฐ ัััะฐัะตะณะธะธ)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

**ะะะะกะขะะ** (ะพัะฒะตั <15 ัะตะบ):
- "ะะพะบะฐะถะธ ะณะพัะพะฒัะต ะฑัะบะตัั"
- "ะกะบะพะปัะบะพ ััะพะธั ะดะพััะฐะฒะบะฐ?"
- "ะะตะถะธะผ ัะฐะฑะพัั?"
โ ะะตะนััะฒะธะต: 1 ะฒัะทะพะฒ ะธะฝััััะผะตะฝัะฐ โ ะพัะฒะตั โ complete

**ะกะะะะะะ** (ะพัะฒะตั 15-30 ัะตะบ):
- "ะัะถะตะฝ ะฑัะบะตั ะฝะฐ ะดะตะฝั ัะพะถะดะตะฝะธั, ะฑัะดะถะตั 15000"
- "ะะฐะบะธะต ัะพะทั ะตััั ะฒ ะฝะฐะปะธัะธะธ?"
โ ะะตะนััะฒะธะต: 1-2 ะฒัะทะพะฒะฐ โ ะดะตัะฐะปัะฝัะน ะพัะฒะตั โ complete

**ะกะะะะะซะ/VIP** (ะพัะฒะตั 30-60 ัะตะบ, ะะะะ ัะพะด):
- "ะะฐะถะฝะฐั ะฒัััะตัะฐ", "ะฑัะดะถะตั ะฝะต ะพะณัะฐะฝะธัะตะฝ", "ะดะพะปะถะฝะพ ะฑััั ะธะดะตะฐะปัะฝะพ"
- ะฃะฟะพะผะธะฝะฐะฝะธะต ัะบัะบะปัะทะธะฒะฝะพััะธ, ััะฐัััะฐ, ะพัะพะฑัั ััะตะฑะพะฒะฐะฝะธะน
โ ะะตะนััะฒะธะต: Extended thinking โ ัะพะฟ-ะฒะฐัะธะฐะฝัั โ ะะะะะะ ะฟัะตะดะปะพะถะตะฝะธะต โ complete
โ โ๏ธ ะะะะขะะงะะ: ะะฐัั ะะกะ ะทะฐ 1 ัะพะด, ะฝะต ัะฐัััะณะธะฒะฐัั ะฝะฐ 2-3 ัะพะดะฐ

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ CHECKLIST ะะะะะ ะะขะะะะะะะ ะะขะะะขะ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

ะะตัะตะด ะบะฐะถะดัะผ ะพัะฒะตัะพะผ ะฟัะพะฒะตัั:
โก ะะฐะป ะปะธ ั ะบะพะฝะบัะตัะฝัะต ะฒะฐัะธะฐะฝัั (ัะพะฒะฐัั/ัะตะฝั)?
โก ะัะฒะตัะธะป ะปะธ ั ะฝะฐ ะะกะ ะฒะพะฟัะพัั ะบะปะธะตะฝัะฐ?
โก ะัะตะดะปะพะถะธะป ะปะธ ั ัะปะตะดัััะธะน ัะฐะณ (ะพัะพัะผะธัั/ะฒัะฑัะฐัั)?
โก ะะพััะฐัะพัะฝะพ ะปะธ ะธะฝัะพัะผะฐัะธะธ ะดะปั ะฟัะธะฝััะธั ัะตัะตะฝะธั?
โก ะะพะณั ะปะธ ั ะทะฐะฒะตััะธัั ัะฐะทะณะพะฒะพั (complete) ะธะปะธ ะฝัะถะตะฝ ะตัะต 1 ัะพะด?

ะัะปะธ ะฝะฐ ะฒัะต ะฒะพะฟัะพัั "ะะ" โ <conversation_status>complete</conversation_status>

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
"""

        instructions_block = {
            "type": "text",
            "text": instructions
        }

        # Return prompt as list of blocks (cacheable format)
        return [catalog_block, policies_block, instructions_block]

    async def chat(
        self,
        messages: List[Dict[str, Any]],
        channel: str = "telegram",
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        Process chat message with Claude AI.

        Args:
            messages: Conversation history (list of {role, content})
            channel: Channel name (telegram, whatsapp, etc)
            context: Optional user context

        Returns:
            Dict with response text and metadata
        """
        import time
        start_time = time.time()  # Track response latency
        self.total_requests += 1

        # Check if cache needs refresh
        if self._should_refresh_cache():
            asyncio.create_task(self._refresh_cache())

        # Build system prompt with caching
        system_prompt = self._build_system_prompt(channel, context)

        # Get tools schema
        tools = self._get_tools_schema()

        # Call Claude API with auto-recovery for corrupted conversation history
        try:
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=2048,
                system=system_prompt,  # โ Blocks with cache_control
                messages=messages,
                tools=tools
            )
        except anthropic.BadRequestError as e:
            # Auto-recover from corrupted conversation history
            # This happens when tool_use_id in tool_result has no corresponding tool_use
            # (e.g., service restarted mid-execution, history saved incorrectly)
            error_message = str(e)
            if "unexpected `tool_use_id`" in error_message or "tool_result" in error_message:
                logger.warning(
                    f"๐ง Detected corrupted conversation history: {error_message[:100]}... "
                    f"Auto-recovering by clearing history and keeping only last user message"
                )

                # Keep only the last user message (discard corrupted tool_use/tool_result pairs)
                last_user_message = None
                for msg in reversed(messages):
                    if msg.get("role") == "user":
                        last_user_message = msg
                        break

                if last_user_message:
                    messages = [last_user_message]
                    logger.info(f"โ Recovered conversation with fresh history (1 message)")

                    # Retry API call with cleaned history
                    response = await self.client.messages.create(
                        model=self.model,
                        max_tokens=2048,
                        system=system_prompt,
                        messages=messages,
                        tools=tools
                    )
                else:
                    logger.error("โ Auto-recovery failed: no user message found in history")
                    raise
            else:
                # Different error, re-raise
                raise

        # Track cache usage
        usage = response.usage
        if hasattr(usage, 'cache_read_input_tokens') and usage.cache_read_input_tokens > 0:
            self.cache_hits += 1
            self.cached_input_tokens += usage.cache_read_input_tokens

        if hasattr(usage, 'input_tokens'):
            self.regular_input_tokens += usage.input_tokens

        # Track cache creation tokens (first request pays premium)
        if hasattr(usage, 'cache_creation_input_tokens'):
            self.cache_creation_tokens += usage.cache_creation_input_tokens

        # Track total tokens per request (for benchmarking)
        total_tokens_used = getattr(usage, 'input_tokens', 0) + getattr(usage, 'output_tokens', 0)
        self.max_tokens_per_request.append(total_tokens_used)

        # Track response latency (for benchmarking)
        elapsed_time = time.time() - start_time
        self.response_times.append(elapsed_time)

        logger.info(f"๐ Cache stats: hits={self.cache_hits}/{self.total_requests} "
                   f"({self.cache_hit_rate:.1f}%), tokens_saved={self.tokens_saved}, latency={elapsed_time:.2f}s")

        return response

    def _should_refresh_cache(self) -> bool:
        """Check if cache should be refreshed."""
        if not self._last_cache_refresh:
            return True

        elapsed = (datetime.now() - self._last_cache_refresh).total_seconds()
        return elapsed >= self.cache_refresh_interval

    @property
    def cache_hit_rate(self) -> float:
        """Calculate cache hit rate percentage."""
        if self.total_requests == 0:
            return 0.0
        return (self.cache_hits / self.total_requests) * 100

    @property
    def tokens_saved(self) -> int:
        """Calculate tokens saved by caching."""
        # Cached tokens cost 10% of regular, so we save 90%
        return int(self.cached_input_tokens * 0.9)

    @property
    def cost_savings_usd(self) -> float:
        """Estimate cost savings in USD."""
        # Claude Sonnet 4.5: $3 per 1M input tokens
        # Cached: $0.30 per 1M (90% savings)
        saved_tokens = self.tokens_saved
        return (saved_tokens / 1_000_000) * 3.0 * 0.9

    def _get_pricing(self, model_name: str) -> Dict[str, float]:
        """Get pricing for different Claude models (USD per 1M tokens)."""
        pricing = {
            # Claude Haiku 4.5 - Ultra-fast, budget-friendly
            "claude-haiku-4-5": {
                "input": 0.80,  # $0.80 per 1M input tokens
                "output": 4.00,  # $4.00 per 1M output tokens
                "cache_read": 0.08,  # $0.08 per 1M cache read (90% discount)
                "cache_write": 1.00  # $1.00 per 1M cache write (25% premium)
            },
            # Claude Sonnet 4.5 - Balanced, high-quality
            "claude-sonnet-4-5": {
                "input": 3.00,  # $3.00 per 1M input tokens
                "output": 15.00,  # $15.00 per 1M output tokens
                "cache_read": 0.30,  # $0.30 per 1M cache read (90% discount)
                "cache_write": 3.75  # $3.75 per 1M cache write (25% premium)
            }
        }

        # Match by partial model name
        for model_key, rates in pricing.items():
            if model_key in model_name:
                return rates

        # Default to Sonnet pricing if model not found
        return pricing["claude-sonnet-4-5"]

    def calculate_cost(self) -> Dict[str, float]:
        """Calculate detailed costs for this service."""
        pricing = self._get_pricing(self.model)

        # Calculate costs
        regular_input_cost = (self.regular_input_tokens / 1_000_000) * pricing["input"]
        cache_read_cost = (self.cached_input_tokens / 1_000_000) * pricing["cache_read"]
        cache_write_cost = (self.cache_creation_tokens / 1_000_000) * pricing["cache_write"]
        output_cost = (sum(getattr(getattr(m, 'usage', {}), 'output_tokens', 0)
                          for m in [] if hasattr(m, 'usage')) / 1_000_000) * pricing["output"]

        # Approximate output cost based on typical response size
        estimated_output_tokens = len(self.response_times) * 300  # ~300 tokens average output
        output_cost = (estimated_output_tokens / 1_000_000) * pricing["output"]

        total_cost = regular_input_cost + cache_read_cost + cache_write_cost + output_cost

        return {
            "regular_input_cost": regular_input_cost,
            "cache_read_cost": cache_read_cost,
            "cache_write_cost": cache_write_cost,
            "output_cost": output_cost,
            "total_cost": total_cost,
            "cost_per_request": total_cost / max(self.total_requests, 1)
        }

    def get_benchmarks(self) -> Dict[str, Any]:
        """Get comprehensive benchmark data for model comparison."""
        import statistics

        costs = self.calculate_cost()
        avg_response_time = statistics.mean(self.response_times) if self.response_times else 0
        avg_tokens_per_request = statistics.mean(self.max_tokens_per_request) if self.max_tokens_per_request else 0

        return {
            "model": self.model,
            "is_haiku": self._is_haiku,
            "is_sonnet": self._is_sonnet,
            "total_requests": self.total_requests,
            "cache_hits": self.cache_hits,
            "cache_hit_rate": self.cache_hit_rate,
            "tokens": {
                "total_input": self.regular_input_tokens + self.cached_input_tokens,
                "regular_input": self.regular_input_tokens,
                "cached_input": self.cached_input_tokens,
                "cache_creation": self.cache_creation_tokens,
                "tokens_saved": self.tokens_saved,
                "avg_tokens_per_request": avg_tokens_per_request
            },
            "costs": costs,
            "performance": {
                "avg_response_time_seconds": avg_response_time,
                "min_response_time_seconds": min(self.response_times) if self.response_times else 0,
                "max_response_time_seconds": max(self.response_times) if self.response_times else 0,
                "total_response_time": sum(self.response_times)
            }
        }

    def _get_tools_schema(self) -> List[Dict[str, Any]]:
        """Get MCP tools schema for function calling."""
        # Import tools schema (we'll create this file next)
        from prompts.tools_schema import get_tools_schema
        return get_tools_schema()

    async def close(self):
        """Close Claude client."""
        await self.client.close()
