"""
AI Client Service - Simulates flower shop customer with persona.
Uses Claude 4.5 with memory and interleaved thinking for realistic behavior.
"""
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from anthropic import Anthropic

import config
from logger_analyzer import TestLogger

logger = logging.getLogger(__name__)


class AIClient:
    """
    AI Client that simulates a customer with specific persona.
    Uses Claude 4.5 with memory for realistic multi-turn conversations.
    """

    def __init__(
        self,
        persona_name: str,
        test_logger: TestLogger,
        initial_goal: str
    ):
        """
        Initialize AI Client with persona.

        Args:
            persona_name: Name of persona JSON file (without .json)
            test_logger: TestLogger instance for logging
            initial_goal: Goal/scenario for this conversation
        """
        self.logger = test_logger
        self.persona_name = persona_name
        self.initial_goal = initial_goal

        # Load persona
        self.persona = self._load_persona(persona_name)

        # Initialize Claude client
        self.client = Anthropic(api_key=config.CLAUDE_API_KEY)
        self.model = config.CLAUDE_MODEL_CLIENT

        # Conversation history
        self.messages: List[Dict[str, Any]] = []

        # Track conversation state
        self.turn_count = 0
        self.goal_achieved = False

        # Memory directory for this client
        self.memory_dir = config.MEMORIES_DIR / "clients"
        self.memory_dir.mkdir(exist_ok=True)

        logger.info(f"ðŸ‘¤ AI Client initialized: {self.persona.get('name', persona_name)}")
        logger.info(f"ðŸŽ¯ Goal: {initial_goal}")

    def _load_persona(self, persona_name: str) -> Dict[str, Any]:
        """Load persona from JSON file."""
        persona_path = config.PERSONAS_DIR / f"{persona_name}.json"

        if not persona_path.exists():
            raise FileNotFoundError(f"Persona not found: {persona_path}")

        with open(persona_path, 'r', encoding='utf-8') as f:
            persona = json.load(f)

        logger.info(f"ðŸ“‹ Loaded persona: {persona.get('name', persona_name)}")
        return persona

    def get_system_prompt(self) -> str:
        """Generate system prompt based on persona."""
        persona = self.persona

        # Extract persona characteristics
        name = persona.get('name', 'ÐšÐ»Ð¸ÐµÐ½Ñ‚')
        persona_type = persona.get('type', 'customer')
        characteristics = persona.get('characteristics', {})
        preferences = persona.get('preferences', {})
        communication_style = persona.get('communication_style', {})
        order_history = persona.get('order_history', [])

        # Build prompt
        prompt = f"""Ð¢Ñ‹ â€” ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ñ†Ð²ÐµÑ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð°. Ð¢Ð²Ð¾Ñ Ñ€Ð¾Ð»ÑŒ: {name}

**Ð¢Ð²Ð¾Ñ Ñ†ÐµÐ»ÑŒ Ð² ÑÑ‚Ð¾Ð¼ Ð´Ð¸Ð°Ð»Ð¾Ð³Ðµ:**
{self.initial_goal}

**Ð¢Ð²Ð¾Ñ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°:**
- Ð¢Ð¸Ð¿ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: {persona_type}
- Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ð¸: {characteristics.get('politeness', 'medium')}
- Ð ÐµÑˆÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {characteristics.get('decisiveness', 'medium')}
- Ð§ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ðº Ð±ÑŽÐ´Ð¶ÐµÑ‚Ñƒ: {characteristics.get('budget_sensitivity', 'medium')}
- Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²: {characteristics.get('question_frequency', 'medium')}

**Ð¢Ð²Ð¾Ð¸ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ñ:**
"""

        if preferences.get('colors'):
            prompt += f"- Ð›ÑŽÐ±Ð¸Ð¼Ñ‹Ðµ Ñ†Ð²ÐµÑ‚Ð°: {', '.join(preferences['colors'])}\n"

        if preferences.get('price_range'):
            price_min, price_max = preferences['price_range']
            prompt += f"- Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {price_min:,} - {price_max:,} Ñ‚ÐµÐ½Ð³Ðµ\n"

        if preferences.get('delivery_time'):
            prompt += f"- ÐŸÑ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸: {preferences['delivery_time']}\n"

        if order_history:
            prompt += f"\n**Ð¢Ð²Ð¾Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð·Ð°ÐºÐ°Ð·Ð¾Ð²:**\n"
            for order in order_history[:3]:  # Last 3 orders
                prompt += f"- {order.get('date')}: {order.get('product')} ({order.get('price'):,}Ñ‚Ð³, Ð¾Ñ†ÐµÐ½ÐºÐ°: {order.get('rating')}/5)\n"

        prompt += f"""
**Ð¡Ñ‚Ð¸Ð»ÑŒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ:**
- ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ: {communication_style.get('greeting', 'neutral')}
- Ð—Ð°Ð¿Ñ€Ð¾ÑÑ‹: {communication_style.get('requests', 'polite')}
- Ð–Ð°Ð»Ð¾Ð±Ñ‹: {communication_style.get('complaints', 'rare')}

**Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°:**
1. Ð’ÐµÐ´Ð¸ ÑÐµÐ±Ñ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾, ÐºÐ°Ðº Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚
2. Ð—Ð°Ð´Ð°Ð²Ð°Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ñ‚Ð²Ð¾ÐµÐ¹ Ð¿ÐµÑ€ÑÐ¾Ð½Ðµ
3. ÐÐµ Ñ‚Ð¾Ñ€Ð¾Ð¿Ð¸ÑÑŒ - Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹ Ð´ÑƒÐ¼Ð°ÑŽÑ‚ Ð¸ ÑÐ¾Ð¼Ð½ÐµÐ²Ð°ÑŽÑ‚ÑÑ
4. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÐ²Ð¾Ð¸ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ñ (Ñ†Ð²ÐµÑ‚Ð°, Ð±ÑŽÐ´Ð¶ÐµÑ‚) Ð² Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ðµ
5. Ð•ÑÐ»Ð¸ Ñ‚Ñ‹ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚ - ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ðµ Ð·Ð°ÐºÐ°Ð·Ñ‹
6. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ
7. ÐŸÐ¸ÑˆÐ¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾ (1-3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð·Ð° Ñ€Ð°Ð·)

**ÐšÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¸ ÑƒÑÐ¿ÐµÑ…Ð°:**
- Ð”Ð¸Ð°Ð»Ð¾Ð³ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¿Ñ€Ð¸Ð²ÐµÑÑ‚Ð¸ Ðº Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸ÑŽ Ñ‚Ð²Ð¾ÐµÐ¹ Ñ†ÐµÐ»Ð¸
- ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ‚ÐµÐ±Ðµ Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼
- Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ñ‚Ñ‹ Ð»Ð¸Ð±Ð¾ Ð¾Ñ„Ð¾Ñ€Ð¼Ð¸ÑˆÑŒ Ð·Ð°ÐºÐ°Ð·, Ð»Ð¸Ð±Ð¾ Ð¾ÑÑ‚Ð°Ð½ÐµÑˆÑŒÑÑ Ð´Ð¾Ð²Ð¾Ð»ÑŒÐ½Ñ‹Ð¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹

ÐÐ°Ñ‡Ð½Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³ ÑÐµÐ¹Ñ‡Ð°Ñ!
"""

        return prompt

    async def generate_initial_message(self) -> str:
        """
        Generate the first message to start conversation.

        Returns:
            Initial greeting/request
        """
        # Add initial context
        self.messages.append({
            "role": "user",
            "content": "ÐÐ°Ñ‡Ð½Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ñ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð¾Ð¼ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð°. ÐŸÑ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒÑÑ Ð¸ ÑÐºÐ°Ð¶Ð¸ Ñ‡Ñ‚Ð¾ Ñ‚ÐµÐ±Ðµ Ð½ÑƒÐ¶Ð½Ð¾."
        })

        # Call Claude
        response = self.client.messages.create(
            model=self.model,
            max_tokens=config.MAX_TOKENS,
            system=self.get_system_prompt(),
            messages=self.messages,
            extra_headers=config.CLAUDE_EXTRA_HEADERS  # Enable memory and interleaved thinking
        )

        # Extract response
        message_text = ""
        for block in response.content:
            if block.type == "thinking":
                # Log thinking block
                self.logger.log_message(
                    sender="client",
                    message_type="thinking",
                    content=block.thinking
                )
            elif block.type == "text":
                message_text += block.text

        # Add to history
        self.messages.append({
            "role": "assistant",
            "content": message_text
        })

        self.turn_count += 1

        return message_text

    async def process_manager_response(
        self,
        manager_message: str
    ) -> Optional[str]:
        """
        Process manager's response and generate next client message.

        Args:
            manager_message: Message from manager

        Returns:
            Client's next message, or None if conversation should end
        """
        # Check if client wants to end conversation
        ending_phrases = [
            "ÑÐ¿Ð°ÑÐ¸Ð±Ð¾, ÑÑ‚Ð¾ Ð²ÑÐµ",
            "Ð±Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€ÑŽ, Ð´Ð¾ ÑÐ²Ð¸Ð´Ð°Ð½Ð¸Ñ",
            "ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ",
            "Ð¿Ð¾Ð½ÑÑ‚Ð½Ð¾, ÑÐ¿Ð°ÑÐ¸Ð±Ð¾"
        ]

        if any(phrase in manager_message.lower() for phrase in ending_phrases):
            self.goal_achieved = True

        # Add manager's message to history
        self.messages.append({
            "role": "user",
            "content": f"ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð»: {manager_message}\n\nÐ¢ÐµÐ¿ÐµÑ€ÑŒ Ñ‚Ð²Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚. Ð•ÑÐ»Ð¸ Ñ‚Ð²Ð¾Ñ Ñ†ÐµÐ»ÑŒ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚Ð° Ð¸Ð»Ð¸ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» Ð½Ð° Ñ‚Ð²Ð¾Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸ 'Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ!'. Ð˜Ð½Ð°Ñ‡Ðµ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³."
        })

        # Call Claude
        response = self.client.messages.create(
            model=self.model,
            max_tokens=config.MAX_TOKENS,
            system=self.get_system_prompt(),
            messages=self.messages,
            extra_headers=config.CLAUDE_EXTRA_HEADERS
        )

        # Extract response
        client_message = ""
        for block in response.content:
            if block.type == "thinking":
                # Log thinking block (shows decision-making)
                self.logger.log_message(
                    sender="client",
                    message_type="thinking",
                    content=block.thinking
                )
            elif block.type == "text":
                client_message += block.text

        # Add to history
        self.messages.append({
            "role": "assistant",
            "content": client_message
        })

        self.turn_count += 1

        # Check if client wants to end
        if any(phrase in client_message.lower() for phrase in ending_phrases):
            self.goal_achieved = True
            return None

        # Limit conversation history
        if len(self.messages) > 30:
            self.messages = self.messages[:2] + self.messages[-28:]

        return client_message

    def should_continue(self, max_turns: int) -> bool:
        """
        Check if conversation should continue.

        Args:
            max_turns: Maximum allowed turns

        Returns:
            True if should continue, False otherwise
        """
        # Stop if goal achieved
        if self.goal_achieved:
            return False

        # Stop if max turns reached
        if self.turn_count >= max_turns:
            return False

        return True

    def get_conversation_analysis(self) -> Dict[str, Any]:
        """
        Analyze conversation from client's perspective.

        Returns:
            Analysis data
        """
        return {
            "persona": self.persona.get('name'),
            "persona_type": self.persona.get('type'),
            "goal": self.initial_goal,
            "goal_achieved": self.goal_achieved,
            "turn_count": self.turn_count,
            "conversation_length": len(self.messages)
        }
