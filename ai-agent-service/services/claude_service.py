"""Claude AI service with Prompt Caching for 80-90% token savings."""

import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import httpx
from anthropic import AsyncAnthropic
import anthropic

logger = logging.getLogger(__name__)


class ClaudeService:
    """
    Claude AI service with Prompt Caching.

    Key features:
    - Caches shop policies/FAQ (~500 tokens)
    - Caches assistant instructions (~2000 tokens)
    - NO product catalog (forces AI to call list_products tool for filtering)
    - Auto-refresh every hour
    - Tracks cache hit rate for monitoring
    """

    def __init__(
        self,
        api_key: str,
        backend_api_url: str,
        shop_id: int,
        model: str = "claude-sonnet-4-5-20250929",
        cache_refresh_interval_hours: int = 1
    ):
        """
        Initialize Claude service.

        Args:
            api_key: Anthropic API key
            backend_api_url: Backend API URL for fetching product catalog
            shop_id: Shop ID for multi-tenancy
            model: Claude model name (e.g., "claude-haiku-4-5-20251001", "claude-sonnet-4-5-20250929")
            cache_refresh_interval_hours: How often to refresh cached catalog
        """
        self.client = AsyncAnthropic(api_key=api_key)
        self.model = model
        self.backend_api_url = backend_api_url.rstrip('/')
        self.shop_id = shop_id
        self.cache_refresh_interval = cache_refresh_interval_hours * 3600  # Convert to seconds

        # Cached data (NO product catalog - forces AI to use list_products tool)
        self._shop_policies: Optional[str] = None
        self._last_cache_refresh: Optional[datetime] = None

        # Cache statistics
        self.total_requests = 0
        self.cache_hits = 0
        self.cached_input_tokens = 0
        self.regular_input_tokens = 0

        # Determine model capabilities
        self._is_haiku = "haiku" in model.lower()
        self._is_sonnet = "sonnet" in model.lower()

        logger.info(f"‚úÖ Claude Service initialized (model={model}, shop_id={shop_id})")
        if self._is_haiku:
            logger.info("üí° Using Claude Haiku 4.5 - optimized for speed and cost efficiency")

    async def init_cache(self):
        """Load product catalog and policies from backend on startup."""
        logger.info("üîÑ Initializing cache...")
        await self._refresh_cache()

    async def _refresh_cache(self):
        """Fetch shop policies (NO product catalog - force AI to use list_products)."""
        try:
            # Fetch shop policies (FAQ, working hours)
            # For MVP, we'll use static policies. In production, fetch from API.
            self._shop_policies = self._get_static_policies()

            self._last_cache_refresh = datetime.now()
            logger.info(f"‚úÖ Cache refreshed: policies loaded (NO product catalog - use list_products tool)")

        except Exception as e:
            logger.error(f"‚ùå Failed to refresh cache: {str(e)}")
            # Don't crash - use empty policies if fetch fails
            self._shop_policies = self._get_static_policies()

    def _get_static_policies(self) -> str:
        """Get static shop policies (FAQ, working hours, etc)."""
        return """
üè™ **–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–ê–ì–ê–ó–ò–ù–ï:**

**–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:**
‚Ä¢ –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫-–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ: 09:00 - 21:00
‚Ä¢ –ë–µ–∑ –≤—ã—Ö–æ–¥–Ω—ã—Ö

**–î–æ—Å—Ç–∞–≤–∫–∞:**
‚Ä¢ –î–æ—Å—Ç–∞–≤–∫–∞ –ø–æ –ê–ª–º–∞—Ç—ã: 2000 ‚Ç∏
‚Ä¢ –î–æ—Å—Ç–∞–≤–∫–∞ –∑–∞ –≥–æ—Ä–æ–¥: –ø–æ –¥–æ–≥–æ–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏
‚Ä¢ –°–∞–º–æ–≤—ã–≤–æ–∑: –±–µ—Å–ø–ª–∞—Ç–Ω–æ (–∞–¥—Ä–µ—Å: –ê–ª–º–∞—Ç—ã, —É–ª. –ê–±–∞—è 150)

**–û–ø–ª–∞—Ç–∞:**
‚Ä¢ –ù–∞–ª–∏—á–Ω—ã–º–∏ –∫—É—Ä—å–µ—Ä—É
‚Ä¢ Kaspi Pay
‚Ä¢ –ë–∞–Ω–∫–æ–≤—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥

**FAQ:**
Q: –ú–æ–∂–Ω–æ –ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å –∑–∞–∫–∞–∑ –ø–æ—Å–ª–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è?
A: –î–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É update_order —Å tracking_id

Q: –ö–∞–∫ –æ—Ç—Å–ª–µ–¥–∏—Ç—å –∑–∞–∫–∞–∑?
A: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Å—ã–ª–∫—É https://cvety-website.pages.dev/status/{tracking_id}

Q: –ö–∞–∫–∏–µ —Ü–≤–µ—Ç—ã —Å–≤–µ–∂–∏–µ?
A: –í—Å–µ –±—É–∫–µ—Ç—ã –∏–∑–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –≤ –¥–µ–Ω—å –¥–æ—Å—Ç–∞–≤–∫–∏ –∏–∑ —Å–≤–µ–∂–∏—Ö —Ü–≤–µ—Ç–æ–≤
"""

    def _build_system_prompt(self, channel: str, context: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        Build system prompt with cached blocks.

        Structure (NO product catalog - forces AI to use list_products tool):
        1. Shop Policies (cached) - ~500 tokens
        2. Assistant Instructions (cached) - ~2000 tokens
        """
        now = datetime.now()
        current_date = now.strftime('%Y-%m-%d')
        current_time = now.strftime('%H:%M')
        day_names_ru = {
            'Monday': '–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', 'Tuesday': '–≤—Ç–æ—Ä–Ω–∏–∫', 'Wednesday': '—Å—Ä–µ–¥–∞',
            'Thursday': '—á–µ—Ç–≤–µ—Ä–≥', 'Friday': '–ø—è—Ç–Ω–∏—Ü–∞', 'Saturday': '—Å—É–±–±–æ—Ç–∞', 'Sunday': '–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ'
        }
        current_day_ru = day_names_ru.get(now.strftime('%A'), now.strftime('%A'))

        # Block 1: Shop Policies (CACHED)
        policies_block = {
            "type": "text",
            "text": self._shop_policies or "",
            "cache_control": {"type": "ephemeral"}  # ‚Üê Cache this block!
        }

        # Block 3: Assistant Instructions (NOT CACHED - can change often)
        # Following Anthropic Best Practices: XML-structured prompt for clarity and maintainability
        instructions = f"""
<role>
–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ü–≤–µ—Ç–æ—á–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞ cvety.kz.
</role>

<context>
**–¢–ï–ö–£–©–ò–ï –î–ê–¢–ê –ò –í–†–ï–ú–Ø:**
- –°–µ–≥–æ–¥–Ω—è: {current_date} ({current_day_ru})
- –°–µ–π—á–∞—Å: {current_time}
</context>

<core_rules>
**–û–°–ù–û–í–ù–´–ï –ü–†–ê–í–ò–õ–ê:**
1. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (list_products, create_order, track_order_by_phone, get_shop_settings)
2. –¶–µ–Ω—ã –ø–æ–∫–∞–∑—ã–≤–∞–π –≤ —Ç–µ–Ω–≥–µ (—Ä–∞–∑–¥–µ–ª—è–π —Ç—ã—Å—è—á–∏ –ø—Ä–æ–±–µ–ª–æ–º: "9 000 ‚Ç∏")
3. –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–∫–∞–∑–∞ —É–º–Ω–æ–∂–∞–π —Ü–µ–Ω—É –Ω–∞ 100 (1 —Ç–µ–Ω–≥–µ = 100 —Ç–∏–π–∏–Ω–æ–≤)
4. –†–∞–∑–ª–∏—á–∞–π –∑–∞–∫–∞–∑—á–∏–∫–∞ (customer) –∏ –ø–æ–ª—É—á–∞—Ç–µ–ª—è (recipient)
5. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π product_id - –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–∑ list_products
6. –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã: "—Å–µ–≥–æ–¥–Ω—è", "–∑–∞–≤—Ç—Ä–∞", "–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞" ‚Üí –ø–µ—Ä–µ–¥–∞–≤–∞–π –∫–∞–∫ –µ—Å—Ç—å –≤ create_order
7. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π —Å–∞–º–æ–≤—ã–≤–æ–∑: delivery_type="pickup"
8. **–ö–†–ò–¢–ò–ß–ù–û**: –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–∫–∞–∑–∞ –í–°–ï–ì–î–ê —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π payment_method="kaspi"
</core_rules>

<personalization>
**–ü–ï–†–°–û–ù–ê–õ–ò–ó–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–ê:**

9. **–ü–†–û–§–ò–õ–¨ –ö–õ–ò–ï–ù–¢–ê (get_client_profile):**
   - –í–°–ï–ì–î–ê –≤—ã–∑—ã–≤–∞–π get_client_profile –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ (–ø—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ –∏—Å—Ç–æ—Ä–∏—è)
   - –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: "–•–æ—Ç–∏—Ç–µ –∫–∞–∫ –æ–±—ã—á–Ω–æ –≤ –≤–∞—à–µ–º –±—é–¥–∂–µ—Ç–µ?"
   - –ü—Ä–æ—Ñ–∏–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç: avg/min/max —á–µ–∫, —Ç–æ–ø-3 –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π —Å –∞–¥—Ä–µ—Å–∞–º–∏, –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–∫–∞–∑–∞

10. **–ê–í–¢–û–ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–û–õ–£–ß–ê–¢–ï–õ–ï–ô:**
    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–µ —É–∫–∞–∑–∞–ª –ø–æ–ª—É—á–∞—Ç–µ–ª—è, –Ω–æ –≤ –ø—Ä–æ—Ñ–∏–ª–µ –µ—Å—Ç—å —Ç–æ–ø-3:
      –ü—Ä–µ–¥–ª–æ–∂–∏: "–î–æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω–æ? –ú–∞—Ä–∏—è (—É–ª. –ê–±–∞—è 87) –∏–ª–∏ –ê–Ω–Ω–∞ (—É–ª. –†–æ–∑—ã–±–∞–∫–∏–µ–≤–∞ 12)?"
    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–∞–∑–≤–∞–ª –∏–º—è –∏–∑ —Ç–æ–ø-3: –ø–æ–¥—Å—Ç–∞–≤—å –Ω–æ–º–µ—Ä –∏ –∞–¥—Ä–µ—Å –ë–ï–ó –ª–∏—à–Ω–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤

11. **GDPR (–ü–†–ò–í–ê–¢–ù–û–°–¢–¨ –î–ê–ù–ù–´–•):**
    - "—É–¥–∞–ª–∏—Ç—å –º–æ–∏ –¥–∞–Ω–Ω—ã–µ" ‚Üí update_profile_privacy(action="delete_profile_data")
    - "–Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–∏–≤—ã—á–∫–∏" ‚Üí update_profile_privacy(action="disable_personalization")
</personalization>

<product_catalog_rules>
**–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï list_products (–ö–†–ò–¢–ò–ß–ù–û!):**

12. **–í–°–ï–ì–î–ê –≤—ã–∑—ã–≤–∞–π list_products –í –°–õ–£–ß–ê–Ø–•:**
   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±—É–∫–µ—Ç: "–ø–æ–∫–∞–∂–∏ –í–µ—Å–µ–Ω–Ω–∏–π" ‚Üí list_products(search="–í–µ—Å–µ–Ω–Ω–∏–π")
   - –ö–∞—Ç–µ–≥–æ—Ä–∏—è: "–ø–æ–∫–∞–∂–∏ —Ä–æ–∑—ã" ‚Üí list_products(search="—Ä–æ–∑")
   - –¶–µ–Ω–∞: "–¥–æ 10000" ‚Üí list_products(max_price=1000000)
   - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–º—è—Ç–∏ - –í–°–ï–ì–î–ê –≤—ã–∑—ã–≤–∞–π list_products!

13. **–ö–û–ì–î–ê –ü–û–ö–ê–ó–´–í–ê–¢–¨ –§–û–¢–û (show_products):**
    ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π <show_products>true</show_products> –µ—Å–ª–∏:
    - –°–ª–æ–≤–∞: "–ø–æ–∫–∞–∂–∏", "—Ö–æ—á—É —É–≤–∏–¥–µ—Ç—å", "–∫–∞–∫–∏–µ –µ—Å—Ç—å"
    - –ù–∞–π–¥–µ–Ω–æ ‚â§5 –±—É–∫–µ—Ç–æ–≤

    ‚ùå –ò—Å–ø–æ–ª—å–∑—É–π <show_products>false</show_products> –µ—Å–ª–∏:
    - –í–æ–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ –æ —Ü–µ–Ω–µ –ë–ï–ó "–ø–æ–∫–∞–∂–∏"
    - –ù–∞–π–¥–µ–Ω–æ >5 –±—É–∫–µ—Ç–æ–≤ (—Å–Ω–∞—á–∞–ª–∞ —Å–ø—Ä–æ—Å–∏)

14. **–õ–ò–ú–ò–¢ –ë–£–ö–ï–¢–û–í:**
    - ‚â§5 –±—É–∫–µ—Ç–æ–≤ ‚Üí <show_products>true</show_products>, –ø–æ–∫–∞–∂–∏ –≤—Å–µ
    - >5 –±—É–∫–µ—Ç–æ–≤ ‚Üí —Å–ø—Ä–æ—Å–∏ –æ –±—é–¥–∂–µ—Ç–µ, –∑–∞—Ç–µ–º list_products(limit=5)
</product_catalog_rules>

<communication_style>
**–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:**
- –ö—Ä–∞—Ç–∫–∏–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π (–Ω–µ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π)
- –≠–º–æ–¥–∑–∏ —É–º–µ—Ä–µ–Ω–Ω–æ (1-2): ‚è≥ ‚úÖ üí∞ üì¶ üåπ
- –û—Ç–≤–µ—á–∞–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª–∏–Ω–µ –∑–∞–ø—Ä–æ—Å–∞
</communication_style>

<telegram_formatting>
**–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –î–õ–Ø TELEGRAM:**
- ‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π Markdown (**, __, *, _) –ù–ò–ö–û–ì–î–ê
- ‚ùå –ù–ï –≤–∫–ª—é—á–∞–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ù–ò–ö–û–ì–î–ê
- ‚ùå –ö–æ–≥–¥–∞ show_products=true: –¢–û–õ–¨–ö–û –∫–æ—Ä–æ—Ç–∫–∞—è —Ñ—Ä–∞–∑–∞ ("–ü–æ–∫–∞–∑—ã–≤–∞—é –±—É–∫–µ—Ç—ã üíê"), –ù–ï –ø–µ—Ä–µ—á–∏—Å–ª—è–π –Ω–∞–∑–≤–∞–Ω–∏—è/—Ü–µ–Ω—ã!
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è: üåπ üíê ‚úÖ üì¶
- ‚úÖ –§–æ—Ä–º–∞—Ç —Ü–µ–Ω: "–ë—É–∫–µ—Ç –ù–µ–∂–Ω–æ—Å—Ç—å ‚Äî 9 500 ‚Ç∏"
</telegram_formatting>

<order_creation>
**–ü–û–°–õ–ï –°–û–ó–î–ê–ù–ò–Ø –ó–ê–ö–ê–ó–ê:**
- –ù–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞ (orderNumber)
- –°—Å—ã–ª–∫–∞: https://cvety-website.pages.dev/status/{{{{tracking_id}}}}
- **–ö–†–ò–¢–ò–ß–ù–û**: "–Ø –æ—Ç–ø—Ä–∞–≤–∏–ª —Å—á–µ—Ç –Ω–∞ –æ–ø–ª–∞—Ç—É –Ω–∞ –≤–∞—à –Ω–æ–º–µ—Ä {{{{phone}}}}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Kaspi."

**–£–¢–û–ß–ù–ï–ù–ò–ï –ê–î–†–ï–°–ê/–í–†–ï–ú–ï–ù–ò:**
- –ê–¥—Ä–µ—Å –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω ‚Üí ask_delivery_address=true
- –í—Ä–µ–º—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ ‚Üí ask_delivery_time=true
- –ù–ï –æ—Ç–∫–∞–∑—ã–≤–∞–π –≤ –∑–∞–∫–∞–∑–µ - –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–ª–∞–≥–∏!
</order_creation>

<kaspi_pay_protocol>
**KASPI PAY - –ü–†–ê–í–ò–õ–ê (–ö–†–ò–¢–ò–ß–ù–û!):**
**–ü–†–ò–ù–¶–ò–ü: –ö–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –§–ê–ö–¢–´, –∞ –Ω–µ —Ä–∞—Å—Å–∫–∞–∑—ã**

- kaspi_check_payment_status ‚Üí "–°—Ç–∞—Ç—É—Å: –û–∂–∏–¥–∞–µ—Ç –æ–ø–ª–∞—Ç—ã ‚è≥"
- kaspi_create_payment ‚Üí "–ü–ª–∞—Ç–µ–∂ 50 ‚Ç∏ —Å–æ–∑–¥–∞–Ω ‚Üí ID: 12673915658 ‚úÖ"
- kaspi_refund_payment ‚Üí "–í–æ–∑–≤—Ä–∞—Ç 30 ‚Ç∏ –≤—ã–ø–æ–ª–Ω–µ–Ω ‚úÖ"
- **–ü–†–ê–í–ò–õ–û:** –ö–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å ‚Üí –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (1 —Å—Ç—Ä–æ–∫–∞)
</kaspi_pay_protocol>

<conversation_efficiency>
**CONVERSATION EFFICIENCY (–ö–†–ò–¢–ò–ß–ù–û!):**

**–¶–ï–õ–¨:** –û—Ç–≤–µ—á–∞—Ç—å –ü–û–õ–ù–û —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞. –ò–∑–±–µ–≥–∞—Ç—å –ª–∏—à–Ω–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏–π.

**–ó–ê–í–ï–†–®–ï–ù–ò–ï (<conversation_status>):**
- complete: –ü–æ–∫–∞–∑–∞–ª —Ç–æ–≤–∞—Ä—ã/—Å–æ–∑–¥–∞–ª –∑–∞–∫–∞–∑/–æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –≤–æ–ø—Ä–æ—Å/–∫–ª–∏–µ–Ω—Ç —Å–∫–∞–∑–∞–ª "—Å–ø–∞—Å–∏–±–æ"
- continue: –ù—É–∂–Ω—ã –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–∫–ª–∏–µ–Ω—Ç –∑–∞–ø—Ä–æ—Å–∏–ª –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
</conversation_efficiency>

<reasoning_framework>
**CHAIN-OF-THOUGHT REASONING (<thinking>):**

–ü–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤ —Ç–µ–≥–∞—Ö <thinking>:
1. –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞ (–ø—Ä–æ—Å—Ç–æ–π/—Å—Ä–µ–¥–Ω–∏–π/—Å–ª–æ–∂–Ω—ã–π/VIP)
2. –ß—Ç–æ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç?
3. –ö–∞–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã?
4. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞?
5. –ï—Å—Ç—å –ª–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ?

**–¢–ò–ü–´ –ó–ê–ü–†–û–°–û–í:**
- –ü–†–û–°–¢–û–ô (<15 —Å–µ–∫): "–ü–æ–∫–∞–∂–∏ –±—É–∫–µ—Ç—ã" ‚Üí 1 –≤—ã–∑–æ–≤ ‚Üí complete
- –°–†–ï–î–ù–ò–ô (15-30 —Å–µ–∫): "–ë—É–∫–µ—Ç –Ω–∞ –î–†, –±—é–¥–∂–µ—Ç 15000" ‚Üí 1-2 –≤—ã–∑–æ–≤–∞ ‚Üí complete
- VIP (30-60 —Å–µ–∫): "–ë—é–¥–∂–µ—Ç –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω, –∏–¥–µ–∞–ª—å–Ω–æ" ‚Üí Extended thinking ‚Üí –í–°–Å –∑–∞ 1 —Ö–æ–¥ ‚Üí complete
</reasoning_framework>

<quality_checklist>
**CHECKLIST –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú:**
‚ñ° –î–∞–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã (—Ç–æ–≤–∞—Ä—ã/—Ü–µ–Ω—ã)?
‚ñ° –û—Ç–≤–µ—Ç–∏–ª –Ω–∞ –í–°–ï –≤–æ–ø—Ä–æ—Å—ã?
‚ñ° –ü—Ä–µ–¥–ª–æ–∂–∏–ª —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥?
‚ñ° –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏?
‚ñ° –ú–æ–≥—É –∑–∞–≤–µ—Ä—à–∏—Ç—å (complete)?
</quality_checklist>

<visual_search_protocol>
**VISUAL SEARCH (MANDATORY!):**

–ü–∞—Ç—Ç–µ—Ä–Ω "[User sent an image: https://...]" ‚Üí **–û–ë–Ø–ó–ê–ù**:
1. **–ù–ï–ú–ï–î–õ–ï–ù–ù–û** search_similar_bouquets(image_url=...)
2. **–î–û–ñ–î–ê–¢–¨–°–Ø** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. **–¢–û–õ–¨–ö–û –ü–û–°–õ–ï** ‚Äî —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç

‚ùå –ù–ï –ú–û–ñ–ï–®–¨:
- –û—Ç–≤–µ—á–∞—Ç—å "–Ω–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å" –ë–ï–ó –≤—ã–∑–æ–≤–∞ search_similar_bouquets
- –ü–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç –î–û –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**–í–†–ï–ú–Ø –ü–û–ò–°–ö–ê:** 5-10 —Å–µ–∫—É–Ω–¥
**API –£–ü–ê–õ:** "–ü–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ"
</visual_search_protocol>
"""

        instructions_block = {
            "type": "text",
            "text": instructions,
            "cache_control": {"type": "ephemeral"}  # Cache instructions too
        }

        # Return prompt as list of blocks (cacheable format)
        return [policies_block, instructions_block]

    def _validate_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Validate and clean message history to prevent tool_use_id errors.

        Rules:
        - Each tool_result must have corresponding tool_use in previous assistant message
        - Remove ONLY orphaned tool_result blocks (selective cleanup)
        - Preserve valid tool_use/tool_result pairs to maintain conversation context
        - This prevents infinite loop bug where AI forgets previous tool calls
        """
        if not messages:
            return messages

        # Collect all tool_use IDs from assistant messages
        valid_tool_use_ids = set()
        has_any_orphaned = False

        for msg in messages:
            if msg.get("role") == "assistant" and isinstance(msg.get("content"), list):
                for block in msg["content"]:
                    if block.get("type") == "tool_use":
                        valid_tool_use_ids.add(block.get("id"))
            elif msg.get("role") == "user" and isinstance(msg.get("content"), list):
                # Check for orphaned tool_results
                for block in msg["content"]:
                    if block.get("type") == "tool_result":
                        tool_use_id = block.get("tool_use_id")
                        if tool_use_id not in valid_tool_use_ids:
                            has_any_orphaned = True
                            logger.warning(f"üîç Found orphaned tool_result for ID: {tool_use_id}")
                            break

        # If we found orphaned blocks, do SELECTIVE cleanup (only remove orphans, keep valid pairs)
        # This prevents infinite loop bug where AI loses context about previous tool calls
        if has_any_orphaned:
            logger.warning("‚ö†Ô∏è SELECTIVE CLEANUP: Removing only orphaned tool_result blocks (keeping valid tool_use/tool_result pairs)")
            # No cleanup here - fall through to selective cleanup below

        # Otherwise, do selective cleanup of orphaned tool_results only
        cleaned_messages = []
        for msg in messages:
            if msg.get("role") == "user" and isinstance(msg.get("content"), list):
                cleaned_content = []
                for block in msg["content"]:
                    if block.get("type") == "tool_result":
                        tool_use_id = block.get("tool_use_id")
                        if tool_use_id in valid_tool_use_ids:
                            cleaned_content.append(block)
                    else:
                        cleaned_content.append(block)

                if cleaned_content:
                    cleaned_messages.append({**msg, "content": cleaned_content})
            else:
                cleaned_messages.append(msg)

        # Final cleanup: Remove empty text blocks from all messages
        final_cleaned = []
        for msg in cleaned_messages:
            if isinstance(msg.get("content"), list):
                # Filter out empty text blocks
                non_empty_content = []
                for block in msg["content"]:
                    if block.get("type") == "text":
                        text = block.get("text", "")
                        if text and text.strip():  # Only keep non-empty text
                            non_empty_content.append(block)
                    else:
                        # Keep all non-text blocks (tool_use, tool_result)
                        non_empty_content.append(block)

                if non_empty_content:
                    final_cleaned.append({**msg, "content": non_empty_content})
                else:
                    logger.warning(f"‚ö†Ô∏è Removed message with only empty text blocks, role={msg.get('role')}")
            elif isinstance(msg.get("content"), str):
                # String content - check if empty
                if msg.get("content") and msg.get("content").strip():
                    final_cleaned.append(msg)
                else:
                    logger.warning(f"‚ö†Ô∏è Removed message with empty string content, role={msg.get('role')}")
            else:
                # Keep other content types
                final_cleaned.append(msg)

        return final_cleaned

    async def chat(
        self,
        messages: List[Dict[str, Any]],
        channel: str = "telegram",
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        Process chat message with Claude AI.

        Args:
            messages: Conversation history (list of {role, content})
            channel: Channel name (telegram, whatsapp, etc)
            context: Optional user context

        Returns:
            Dict with response text and metadata
        """
        import time
        start_time = time.time()  # Track response latency
        self.total_requests += 1

        # Check if cache needs refresh
        if self._should_refresh_cache():
            asyncio.create_task(self._refresh_cache())

        # Build system prompt with caching
        system_prompt = self._build_system_prompt(channel, context)

        # Get tools schema
        tools = self._get_tools_schema()

        # Validate and clean message history before sending to API
        messages = self._validate_messages(messages)

        # Call Claude API with auto-recovery for corrupted conversation history
        try:
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=2048,
                system=system_prompt,  # ‚Üê Blocks with cache_control
                messages=messages,
                tools=tools
            )
        except anthropic.BadRequestError as e:
            # Auto-recover from corrupted conversation history
            # This happens when:
            # 1. tool_use_id in tool_result has no corresponding tool_use
            # 2. Empty text content blocks in message history
            # (e.g., service restarted mid-execution, history saved incorrectly)
            error_message = str(e)
            if ("unexpected `tool_use_id`" in error_message or
                "tool_result" in error_message or
                "text content blocks must be non-empty" in error_message or
                "must be non-empty" in error_message):
                logger.warning(
                    f"üîß Detected corrupted conversation history: {error_message[:100]}... "
                    f"Auto-recovering by clearing history and keeping only last user message"
                )

                # Keep only the last user message (discard corrupted tool_use/tool_result pairs)
                last_user_message = None
                for msg in reversed(messages):
                    if msg.get("role") == "user":
                        # Extract only plain text content, discard tool_result blocks
                        if isinstance(msg.get("content"), list):
                            for block in msg["content"]:
                                if block.get("type") == "text":
                                    last_user_message = msg
                                    break
                        elif isinstance(msg.get("content"), str):
                            last_user_message = msg
                            break

                if last_user_message:
                    messages = [last_user_message]
                    logger.info(f"‚úÖ Recovered conversation with fresh history (1 message)")

                    # Retry API call with cleaned history
                    response = await self.client.messages.create(
                        model=self.model,
                        max_tokens=2048,
                        system=system_prompt,
                        messages=messages,
                        tools=tools
                    )
                else:
                    logger.error("‚ùå Auto-recovery failed: no user message found in history")
                    raise
            else:
                # Different error, re-raise
                raise

        # Track cache usage
        usage = response.usage
        if hasattr(usage, 'cache_read_input_tokens') and usage.cache_read_input_tokens > 0:
            self.cache_hits += 1
            self.cached_input_tokens += usage.cache_read_input_tokens

        if hasattr(usage, 'input_tokens'):
            self.regular_input_tokens += usage.input_tokens

        # Track response latency for logging
        elapsed_time = time.time() - start_time

        logger.info(f"üìä Cache stats: hits={self.cache_hits}/{self.total_requests} "
                   f"({self.cache_hit_rate:.1f}%), tokens_saved={self.tokens_saved}, latency={elapsed_time:.2f}s")

        return response

    def _should_refresh_cache(self) -> bool:
        """Check if cache should be refreshed."""
        if not self._last_cache_refresh:
            return True

        elapsed = (datetime.now() - self._last_cache_refresh).total_seconds()
        return elapsed >= self.cache_refresh_interval

    @property
    def cache_hit_rate(self) -> float:
        """Calculate cache hit rate percentage."""
        if self.total_requests == 0:
            return 0.0
        return (self.cache_hits / self.total_requests) * 100

    @property
    def tokens_saved(self) -> int:
        """Calculate tokens saved by caching."""
        # Cached tokens cost 10% of regular, so we save 90%
        return int(self.cached_input_tokens * 0.9)

    @property
    def cost_savings_usd(self) -> float:
        """Estimate cost savings in USD."""
        # Claude Sonnet 4.5: $3 per 1M input tokens
        # Cached: $0.30 per 1M (90% savings)
        saved_tokens = self.tokens_saved
        return (saved_tokens / 1_000_000) * 3.0 * 0.9

    def _get_tools_schema(self) -> List[Dict[str, Any]]:
        """Get MCP tools schema for function calling."""
        # Import tools schema (we'll create this file next)
        from prompts.tools_schema import get_tools_schema
        return get_tools_schema()

    async def close(self):
        """Close Claude client."""
        await self.client.close()
